# 简介

本脚本通过将各种随机噪声模型应用于原始数据集，来生成金融市场数据的“平行历史”。它旨在为交易策略的稳健性回测、压力测试和蒙特卡洛模拟创建逼真的、可用于替代历史的合成数据集。基于不同目的，我给出了3种生成方式，各自有一定优势。
- 引力GBM模式: 通过调节参数，可以连续的控制平行历史数据和真实价格数据的游离程度。
- GARCH模式: 现代应用广泛，成熟的金融噪声建模。可以通过参数控制整体波动率缩放
- 异常注入模式：在原始历史数据的基础上注入黑天鹅事件，检测策略的抗风险能力


# 代码工作流程

脚本按以下顺序运行：

1.  **配置**：用户在 `generate_parallel_data.py` 脚本的顶部定义输入/输出路径、选择生成模式并调整模型参数。
2.  **加载原始数据**：脚本从预处理的 `.pkl` 文件中加载现货和永续合约市场的预处理历史数据。
3.  **并行处理**：为了加速生成过程，脚本使用除一个核心外的所有可用CPU核心，并行处理每个交易对的数据。
4.  **应用噪声模型**：根据所选模式，将特定的噪声生成函数应用于每个交易对的OHLC（开、高、低、收）价格序列。
5.  **确保数据一致性**：在修改价格后，脚本会调整相关的数据字段（如 `volume`, `quote_volume`, `trade_num` 等），以确保整个数据集的内在逻辑保持一致。
6.  **保存输出**：新生成的“平行世界”被保存在 `Output/` 文件夹下的一个专用目录中。输出内容包括完整的字典数据和与原始数据时间范围对齐的、方便分析的透视表。

---

# 科学的生成模式
合理，科学的噪声/异常生成依赖于对价格模型本身的理解。我们先从介绍经典的价格建模开始。

## 金融价格序列的经典模型：几何布朗运动 (GBM)

在金融工程领域，**几何布朗运动 (Geometric Brownian Motion, GBM)** 是描述股价、汇率等金融资产价格随时间演变的最经典、最基础的数学模型。其核心思想是，资产价格的连续复利收益率服从一个带有固定漂移和波动的随机过程。大名鼎鼎的BSM期权定价公式就是假设价格遵循该模型。

其数学公式为：
$$ dS_t = \mu S_t dt + \sigma S_t dW_t $$
其中：
- $S_t$ 是资产在 $t$ 时刻的价格。
- $\mu$ 是**漂移率**，代表资产价格的平均增长趋势。
- $\sigma$ 是**波动率**，代表资产价格的不确定性或风险水平。
- $dW_t$ 布朗运动的增量，可以看作是随机冲击的来源。

然而，标准的GBM模型有其局限性：它假设**漂移率 $\mu$ 和波动率 $\sigma$ 在整个时间段内都是恒定不变的**。这与真实市场不符，因为真实市场的波动性是随时间动态变化的（存在“波动率聚集”现象），并且价格路径也不会无限地偏离其基本价值。

本脚本中的`引力GBM模式`和`GARCH模式`正是为了克服这些局限性而设计的。

---
## 1. 引力GBM模式 (`GBM_Gravity`)

-   **原理与改进**:
    这是我自创的一个方法。
    此模式基于标准的GBM模型，但进行了一项关键改进：引入了一个 **引力项 ～ G**。标准的GBM模拟路径可能会因为随机性而无限偏离真实的、已发生的价格路径。引力项的作用是**不断将模拟生成的价格拉回到原始的真实历史价格附近**。
    这种改进解决了GBM模型可能产生完全不切实际价格路径的问题，使得生成的并行历史在保持随机性的同时，更贴近于“可能发生但未发生”的合理范围。

-   **参数 (`CUSTOM_PARAMETERS['GBM_Gravity']`)**:
    -   `sigma_scale` (float): 历史波动率的乘数。`1.0` 表示使用原始波动率，`<1.0` 会抑制波动，`>1.0` 则会放大随机波动。
    -   `G` (float): 引力系数。值越高，模拟价格被拉向原始价格的力量就越强，模拟路径与真实路径的相似度也就越高。若设为 `0`，则退化为标准GBM模型；若数值非常大，则会生成和原始数据类似的历史数据。

-  **特点**:
    - 原创的生成方法，通过调整`sigma_scale`和`G`， 你可以“连续的”控制平行历史价格相对于真实历史价格的游离程度。

## 2. GARCH模式 (`GARCH`)

-   **原理与改进**:
    此模式旨在解决标准GBM模型“恒定波动率”的根本缺陷。**GARCH (广义自回归条件异方差)** 模型专门用于捕捉金融时间序列中**“波动率聚集”**的特性——即市场在一段时期内的高波动之后往往伴随着高波动，平静之后则继续平静。
    脚本会首先用GARCH(1,1)模型拟合历史数据，得到一个随时间动态变化的条件波动率序列。然后，它使用这个更逼真的、时变的波动率来生成价格噪声。这使得GARCH模式比GBM能产生更真实的波动动态。

-   **参数 (`CUSTOM_PARAMETERS['GARCH']`)**:
    -   `sigma_scale` (float): 应用于GARCH模型预测的条件波动率的缩放因子。它允许你全局性地放大或缩小市场的整体波动水平。

-  **特点**:
    - 现代，成熟，应用广泛的建模方法。

## 3. 异常注入模式 (`Anomaly_Injection`)

-   **原理**:
    此模式用于模拟市场冲击、闪电崩盘或“黑天鹅”事件。它通过三个阶段运作：
    1.  **冲击**: 在随机的时间点，注入一个巨大的、瞬时的价格跳跃（向上或向下）。跳跃的幅度基于该资产历史**风险价值（VaR）**的倍数，使得冲击大小与该资产自身的风险状况成正比。
    2.  **恢复**: 冲击发生后，价格会在一个设定的时间段内逐渐恢复到其原始价格序列。这模拟了市场的自我修正机制。
    3.  **交易量飙升**: 在异常事件和初始恢复期间，交易量及相关指标会被人为放大，以模拟此类事件中典型的市场活跃度激增现象。

-   **参数 (`CUSTOM_PARAMETERS['Anomaly_Injection']`)**:
    -   `anomaly_prob` (浮点数): 在任何给定的时间点，单个交易对发生异常事件的概率。例如，`0.02` 意味着每小时有2%的概率发生。
    -   `recovery_hours` (整数): 冲击发生后，价格逐渐恢复到正常路径所需的总小时数。

- **特点**:
    -  通过注入更多极端事件检测策略的综合稳定性。策略在这类数据集中表现的更烂是几乎肯定的，但是确实是很好的风险监测方法。


---

## 数据合理以及一致性保障机制
注意到以上随机方法仅修改了价格序列，但对别的交易量相关数据并没有修正。同时我们也需要保证OHLC价格关系的合理性。
为确保生成的并行历史数据在修改价格后仍保持合理性和内在逻辑一致性，
脚本实施了一套完整的数据校正机制：

### 1. 价格约束
所有噪声生成函数都会在最后强制执行OHLC（开高低收）价格的基本约束关系：
- **最高价约束**: `high` ≥ `max(open, close)` - 确保最高价不低于开盘价和收盘价中的较高者
- **最低价约束**: `low` ≤ `min(open, close)` - 确保最低价不高于开盘价和收盘价中的较低者
- **价格正值约束**: 所有价格都被强制为正值（最小值设为1e-8），避免出现零或负价格

### 2 平均价格字段重新计算
- **`avg_price_1m`**: 基于新OHLC重新计算为 `open×0.8 + high×0.05 + low×0.05 + close×0.1`
- **`avg_price_5m`**: 重新计算为 `open×0.7 + high×0.05 + low×0.05 + close×0.2`

### 3. 交易数据自动调整 (`adjust_linked_fields` 函数)

#### 3.1 成交量相关字段协同调整机制
- **基础成交量保持**: `volume`（基础资产成交量）保持原值作为锚点
- **报价成交量重新计算**: `quote_volume` = `volume × 新平均价格 × 原始比例 × (1 + 小幅随机噪声)`
  - 这确保了成交量与价格变化的合理关联性, 我们知道`quote_volume/volume` 得到的是该小时的vwap，所以在生成新的价格后我们将就此原理模拟生成新的`quote volume`和`volume`。
  - 添加1%的随机噪声模拟真实市场的微小波动
``` python
    # Adjust volume-related fields based on price changes
    if 'volume' in df.columns and 'quote_volume' in df.columns:
        # Calculate current average price for volume adjustment
        avg_price = (df['open'] + df['high'] + df['low'] + df['close']) / 4
        # Keep the ratio but add some noise
        original_ratio = df['quote_volume'] / (df['volume'] * avg_price + 1e-8)
        df['quote_volume'] = df['volume'] * avg_price * original_ratio * (1 + np.random.normal(0, 0.01, len(df)))
```
#### 3.2 交易活动指标的比例关系保持调整
接下来是如何科学生成`trade_num，
taker_buy_base_asset_volume，taker_buy_quote_asset_volume` 数据。

简单地为交易活动指标添加随机噪声会破坏市场微观结构的内在逻辑关系，可能导致：
- 交易笔数与成交额不成比例（如巨额交易只有几笔，或小额交易有数千笔）
- 主动买入比例失真，无法反映真实的买卖压力
- 不同字段间缺乏协调性，数据看起来"不自然"

为了更准确地反映市场微观结构，脚本不再简单地为交易活动字段添加随机噪声，而是基于原始数据的内在比例关系来生成新值：

**2.2.1 交易笔数调整 (`trade_num`)**
- **原理**: 保持 `quote_volume / trade_num` 的比例关系（即平均每笔交易金额）
- **方法**: `新trade_num = 新quote_volume / (原始平均交易金额 × (1 ± 5%随机变动))`
- **意义**: 确保交易频率与市场活跃度的合理关联

**2.2.2 主动买入量调整**
- **报价资产主动买入** (`taker_buy_quote_asset_volume`):
  - 保持 `taker_buy_quote_asset_volume / quote_volume` 的比例（买卖压力指标）
  - `新主动买入报价量 = 新quote_volume × 原始买入比例 × (1 ± 3%随机变动)`
  
- **基础资产主动买入** (`taker_buy_base_asset_volume`):
  - 保持 `taker_buy_base_asset_volume / volume` 的比例
  - `新主动买入基础量 = 新volume × 原始买入比例 × (1 ± 3%随机变动)`

**2.2.3 实现代码示例**
```python
# 交易笔数调整
original_avg_trade_size = df['quote_volume'] / (df['trade_num'] + 1e-8)
trade_size_variation = 1 + np.random.normal(0, 0.05, len(df))
df['trade_num'] = df['quote_volume'] / (original_avg_trade_size * trade_size_variation)

# 主动买入比例调整
original_buy_ratio = df['taker_buy_quote_asset_volume'] / (df['quote_volume'] + 1e-8)
buy_ratio_variation = 1 + np.random.normal(0, 0.03, len(df))
df['taker_buy_quote_asset_volume'] = df['quote_volume'] * original_buy_ratio * buy_ratio_variation
```

#### 3.4 逻辑约束强制执行
- **主动买入约束**: `taker_buy_base_asset_volume` ≤ `volume`
- **主动买入报价约束**: `taker_buy_quote_asset_volume` ≤ `quote_volume`
- **非负性约束**: 所有成交量相关字段都被强制为非负值
- **最小交易笔数**: `trade_num` 至少为1，确保有交易发生

### 4. 异常情况下的特殊处理

#### 4.1 异常注入模式的成交量放大
在异常注入模式中，除了价格冲击外，还会模拟异常事件期间的交易活跃度激增：
- **成交量放大**: 在异常发生后的前几个小时，成交量按 `(1 + |价格跳跃幅度| × 5)` 的倍数放大
- **衰减机制**: 放大效应随时间指数衰减，模拟市场逐渐恢复正常的过程

#### 4.2 数据不足时的保守处理
- 当历史数据不足以进行可靠的统计分析时（如GARCH模型需要至少20个数据点），脚本会回退到更简单但稳健的噪声生成方法
- 设置保守的默认参数，避免产生过于极端的价格变动

### 5. 时间对齐保证
生成的透视表（pivot tables）严格与原始数据的时间范围对齐，确保：
- 时间索引完全一致
- 不会出现时间跳跃或缺失
- 便于与原始数据进行直接比较和分析

---

# 如何使用

1.  **配置**: 打开 `generate_parallel_data.py` 并根据需要调整配置：
    -   `raw_data_path`: 你的输入数据路径。
    -   `processed_data_path`: 用于创建输出文件夹的路径。
    -   `GENERATION_MODES`: 你希望运行的模式列表。
    -   `GENERATION_COUNT`: 每个模式要生成的世界数量。
    -   `CUSTOM_PARAMETERS`: 微调每个模式的参数。
2.  **安装依赖**:
    ```bash
    pip install -r requirements.txt
    ```
3.  **运行脚本**:
    ```bash
    python generate_parallel_data.py
    ```

脚本将打印其进度，并将结果保存在 `Output/<mode_name>_<world_number>/` 目录中。 